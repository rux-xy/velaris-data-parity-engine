
# ğŸ“Š Velaris Data Parity Engine

### **Automated Data Quality Validation for Velaris Integrations**

The **Velaris Data Parity Engine** is a Python-based validation framework that analyzes data consistency between **Velaris** and external systems (Salesforce, HubSpot, Stripe, etc.).
It performs **field-level** and **record-level** parity checks, highlights mismatches, and generates detailed output reports automatically.

This project is developed for the **Velaris Data Quality Hackathon 2025**.

---

# ğŸ“ Project Folder Structure

```
velaris-data-parity-engine/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ (global config files)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bookings/
â”‚   â”‚   â”œâ”€â”€ SF Custom Object - Bookings to Velaris Custom Object _ DataIQ.csv
â”‚   â”‚   â””â”€â”€ SF Custom Object - Bookings to Velaris Custom Object _ DataIQ.xlsx
â”‚   â”‚
â”‚   â”œâ”€â”€ opportunities/
â”‚   â”‚   â””â”€â”€ Salesforce to Velaris Opportunity _ Uberall.xlsx
â”‚   â”‚
â”‚   â”œâ”€â”€ subscriptions/
â”‚   â”‚   â””â”€â”€ Corporate Subscriptions to Velaris _ Salesforce.xlsx
â”‚   â”‚
â”‚   â””â”€â”€ mappings/
â”‚       â”œâ”€â”€ bookings.json
â”‚       â”œâ”€â”€ opportunities.json
â”‚       â””â”€â”€ subscriptions.json
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ bookings/
â”‚   â”œâ”€â”€ opportunities/
â”‚   â””â”€â”€ subscriptions/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ (engine logic)
â”‚   â”‚
â”‚   â”œâ”€â”€ validators/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ batch_runner.py
â”‚   â”‚   â””â”€â”€ multi_validator.py
â”‚   â”‚
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ pyvenv.cfg
```

---

# ğŸš€ What This Engine Does

### âœ” Reads input data

From `/data/<object>/...` (Bookings, Opportunities, Subscriptions)

### âœ” Loads validation rules

From `/data/mappings/*.json`
These define:

* Velaris field â†” Salesforce field mappings
* Data type rules
* Required fields
* Keys for merging

### âœ” Runs parity checks

The validators detect:

* Missing records
* Mismatched values
* Duplicate keys
* Unexpected schema changes
* Fields with null/empty anomalies

### âœ” Saves results

Results are stored in `/output/<object>/...` as:

* mismatch reports
* missing record lists
* summary logs

### âœ” Supports batch or multi-file validation

* `batch_runner.py` â†’ run validator for one dataset
* `multi_validator.py` â†’ validate Bookings, Opportunities, Subscriptions in one go

---

# ğŸ§  How the System Works

### **1. Load raw data**

From Excel/CSV under `data/<object>/`

### **2. Load mapping**

Used to align Salesforce fields to Velaris fields.

### **3. Merge & Compare**

Record-level join using a configured primary key.

### **4. Identify Issues**

Validator checks:

* Null values
* Type mismatches
* Field mismatches
* Missing Salesforce â†’ Velaris records
* Extra Velaris records

### **5. Output Reports**

Stored under `output/<object>/`

---

# â–¶ï¸ Running the Validator

### 1ï¸âƒ£ Install dependencies

```
pip install -r src/requirements.txt
```

### 2ï¸âƒ£ Run batch validation

```
python src/validators/batch_runner.py
```

### 3ï¸âƒ£ Run full (multi-object) validation

```
python src/validators/multi_validator.py
```

---

# âš™ï¸ Configuration Files

### ğŸ“Œ Mappings (`data/mappings/*.json`)

Define:

* Column mappings
* Key fields
* Ignore lists
* Tolerance rules

Example:

```json
{
  "primary_key": "Booking ID",
  "mappings": {
    "Velaris Field": "Salesforce Field"
  }
}
```

---

# ğŸ“¬ Outputs

For each object (bookings, opportunities, subscriptions), the tool generates:

| File                        | Description                              |
| --------------------------- | ---------------------------------------- |
| `mismatches.csv`            | Field-level mismatches                   |
| `missing_in_salesforce.csv` | Exists in Velaris, missing in Salesforce |
| `missing_in_velaris.csv`    | Exists in Salesforce, missing in Velaris |
| `summary.json`              | Quick overview of counts                 |

---

# â˜ï¸ Deployment Notes

You can deploy this on AWS via:

* **Lambda** (for small datasets)
* **EC2** (cron-based execution)
* **ECS/Fargate** (production-ready)
* **S3 input + EventBridge** (serverless scheduled validation)

---

# ğŸ‘¥ Team

**Rumeth**, **Subanya**, **Sandali**
Velaris Data Quality Project

---


